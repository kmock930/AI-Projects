{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #import numpy library\n",
    "ionosphere=np.genfromtxt(\"ionosphere.txt\",delimiter=\",\") #load data from textfile\n",
    "\n",
    "#load iris dataset and related methods\n",
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucliDistance(training,test):\n",
    "    '''It calculates the euclidean distance of two vectors'''\n",
    "    if (training.size==test.size):\n",
    "        arrlen=training.size\n",
    "        sum=0\n",
    "        for i in range(0,arrlen):\n",
    "            sum+=(training[i]-test[i])**2\n",
    "        return sqrt(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def NNClassifier(trainset,trainlabels,testTarget):\n",
    "    '''It finds the training sample with the min distance from the test sample.'''\n",
    "    distances=list()\n",
    "    for train_row in trainset:\n",
    "        distances.append(eucliDistance(train_row,testTarget))\n",
    "    minDist=math.inf\n",
    "    curPos=0\n",
    "    for i in range(0,len(distances)):\n",
    "        if (distances[i]<minDist):\n",
    "            minDist=distances[i]\n",
    "            curPos=i\n",
    "    return (minDist,trainlabels[curPos]) #minDist,(predicted) label of the closest vecctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfScore(sampleset,labelset,targetSample,targetClass,targetIdx):\n",
    "    if (sampleset.shape[0]!=labelset.shape[0]):\n",
    "        return \"Invalid size of sample set or label set!\"\n",
    "    diffClassSamples=list() #list of samples from different class\n",
    "    diffClassLabels=list()\n",
    "    sameClassSamples=list() #list of samples from same class\n",
    "    sameClassLabels=list()\n",
    "    for i in range(sampleset.shape[0]):\n",
    "        if (i!=targetIdx):\n",
    "            if (labelset[i]==targetClass):\n",
    "                sameClassSamples.append(sampleset[i])\n",
    "                sameClassLabels.append(labelset[i])\n",
    "            else:\n",
    "                diffClassSamples.append(sampleset[i])\n",
    "                diffClassLabels.append(labelset[i])\n",
    "    conformityScore=NNClassifier(diffClassSamples,diffClassLabels,targetSample)[0]\n",
    "    try:\n",
    "        conformityScore/=NNClassifier(sameClassSamples,sameClassLabels,targetSample)[0]\n",
    "    except ZeroDivisionError:\n",
    "        return math.inf\n",
    "    return conformityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAllCfScores(trainsamples,trainlabels,testsamples,postlabels):\n",
    "    #concatenate trainsamples and testsamples\n",
    "    for i in range(trainsamples.shape[0]):\n",
    "        extrasamples=np.concatenate((trainsamples,testsamples),axis=0)\n",
    "    #also concatenate trainlabels and postlabels\n",
    "    for i in range(trainlabels.shape[0]):\n",
    "        extralabels=np.concatenate((trainlabels,postlabels),axis=0)\n",
    "    #cur cf --> call cfScore()\n",
    "    cfscores=np.array([])\n",
    "    for k in range(0,extrasamples.shape[0]):\n",
    "        targetSample=extrasamples[k]\n",
    "        targetClass=extralabels[k]\n",
    "        curCf=cfScore(extrasamples,extralabels,targetSample,targetClass,k)\n",
    "        cfscores=np.append(cfscores,curCf) #add cur cf to list\n",
    "    return cfscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(target,arr):\n",
    "    '''give the rank for an item in array: smallest (1) to largest (n).'''\n",
    "    allItems=set()\n",
    "    for item in arr:\n",
    "        allItems.add(item)\n",
    "    if (target not in allItems):\n",
    "        return None #error\n",
    "    rank=1\n",
    "    for uniqItem in allItems:\n",
    "        if (uniqItem==target):\n",
    "            return rank\n",
    "        else:\n",
    "            if (uniqItem<target):\n",
    "                rank+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgFalsePVal(train_size,test_size,sampleset,labelset,truelabelset,cfScores):\n",
    "    if (train_size+test_size!=sampleset.shape[0]):\n",
    "        return \"Invalid train size or test size!\"\n",
    "    if (sampleset.shape[0]!=labelset.shape[0]!=cfScores.shape[0]):\n",
    "        return \"Invalid size of either sample set, label set, or conformity scores list!\"\n",
    "    pVals=np.zeros(cfScores.shape[0])\n",
    "    for i in range(0,pVals.shape[0]):\n",
    "        #rank each cf score\n",
    "        curRank=rank(cfScores[i],cfScores)\n",
    "        #calc p value\n",
    "        curPVal=curRank/cfScores.shape[0]\n",
    "        #add to p values list\n",
    "        pVals[i]=curPVal\n",
    "    avg=0\n",
    "    for i in range(train_size,pVals.shape[0]):\n",
    "        if (labelset[i]!=truelabelset[i-train_size]):\n",
    "            #a false p value is found\n",
    "            pval=pVals[i]\n",
    "            avg+=pval\n",
    "    avg/=cfScores.shape[0]\n",
    "    return (avg,pVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-177-dec3fb040402>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-177-dec3fb040402>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    return cf_prediction​\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "def displayResults(xtrain,ytrain,xtest,ytest):\n",
    "    cf_prediction={\"p-values\":[],\"Predicted list\":[],\"Average False P-value\":0,\"Error Rate\":0,\"Number of errors\":0}\n",
    "    \n",
    "    xtest_rows,xtest_cols=xtest.shape\n",
    "    y_pred=np.zeros(xtest_rows)\n",
    "    for k in range(0,xtest_rows):\n",
    "        y_pred[k]=NNClassifier(X_train,y_train,X_test[k])[1]\n",
    "    errRate=1-np.mean(y_pred==y_test)\n",
    "    cf_prediction[\"Predicted list\"]=y_pred\n",
    "    cf_prediction[\"Error Rate\"]=errRate\n",
    "    cf_prediction[\"Number of errors\"]=int(errRate*xtest_rows)\n",
    "    \n",
    "    for i in range(0,X_train.shape[0]):\n",
    "        extrasamples=np.concatenate((X_train,X_test),axis=0)\n",
    "    for j in range(0,y_train.shape[0]):\n",
    "        extralabels=np.concatenate((y_train,y_pred),axis=0)\n",
    "    cfScores=findAllCfScores(X_train,y_train,X_test,y_pred)\n",
    "    cf_prediction[\"Average False P-value\"]=avgFalsePVal(X_train.shape[0],X_test.shape[0],extrasamples,extralabels,y_test,cfScores)[0]\n",
    "    cf_prediction[\"p-values\"]=avgFalsePVal(X_train.shape[0],X_test.shape[0],extrasamples,extralabels,y_test,cfScores)[1]\n",
    "    return cf_prediction​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p-values': array([0.10666667, 0.06666667, 0.03333333, 0.05333333, 0.1       ,\n",
       "        0.06      , 0.02      , 0.02      , 0.02      , 0.12666667,\n",
       "        0.09333333, 0.04666667, 0.04      , 0.06666667, 0.07333333,\n",
       "        0.01333333, 0.04666667, 0.11333333, 0.00666667, 0.06      ,\n",
       "        0.18      , 0.43333333, 0.06      , 0.43333333, 0.56666667,\n",
       "        0.1       , 0.11333333, 0.11333333, 0.07333333, 0.01333333,\n",
       "        0.10666667, 0.31333333, 0.15333333, 0.30666667, 0.12      ,\n",
       "        0.12666667, 0.19333333, 0.04666667, 0.21333333, 0.34      ,\n",
       "        0.19333333, 0.17333333, 0.1       , 0.16      , 0.33333333,\n",
       "        0.10666667, 0.02666667, 0.22666667, 0.18      , 0.10666667,\n",
       "        0.18666667, 0.36      , 0.05333333, 0.24      , 0.20666667,\n",
       "        0.06      , 0.03333333, 0.23333333, 0.04      , 0.10666667,\n",
       "        0.66      , 0.12      , 0.16      , 0.23333333, 0.1       ,\n",
       "        0.00666667, 0.6       , 0.51333333, 0.33333333, 0.18      ,\n",
       "        0.15333333, 0.8       , 0.19333333, 0.32666667, 0.20666667,\n",
       "        0.01333333, 0.16666667, 0.24666667, 0.02      , 0.55333333,\n",
       "        0.22666667, 0.07333333, 0.24      , 0.76666667, 0.18      ,\n",
       "        0.00666667, 0.04      , 0.09333333, 0.68      , 0.51333333,\n",
       "        0.02666667, 0.07333333, 0.32666667, 0.52      , 0.07333333,\n",
       "        0.23333333, 0.72666667, 0.40666667, 0.04      , 0.35333333,\n",
       "        0.05333333, 0.84      , 0.18666667, 0.24      , 0.66      ,\n",
       "        0.21333333, 0.02666667, 0.22666667, 0.07333333, 0.32      ,\n",
       "        0.21333333, 0.26      , 0.06666667, 0.37333333, 0.36666667,\n",
       "        0.7       , 0.68666667, 0.30666667, 0.38      , 0.18      ,\n",
       "        0.66      , 0.07333333, 0.6       , 0.05333333, 0.51333333,\n",
       "        0.46      , 0.11333333, 0.07333333, 0.37333333, 0.04666667,\n",
       "        0.72666667, 0.27333333, 0.09333333, 0.04666667, 0.62666667,\n",
       "        0.71333333, 0.22      , 0.24666667, 0.12666667, 0.14      ,\n",
       "        0.56666667, 0.00666667, 0.62      , 0.14666667, 0.85333333,\n",
       "        0.18      , 0.46      , 0.14      , 0.04      , 0.08      ]),\n",
       " 'Predicted list': array([2., 0., 1., 0., 1., 1., 2., 1., 2., 1., 2., 2., 2., 2., 2., 1., 0.,\n",
       "        2., 0., 0., 0., 2., 0., 0., 0., 2., 0., 2., 0., 1., 0., 2., 0., 1.,\n",
       "        0., 1., 2., 2.]),\n",
       " 'Average False P-value': 0.00035555555555555557,\n",
       " 'Error Rate': 0.052631578947368474,\n",
       " 'Number of errors': 2}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction of iris dataset\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris['data'],iris['target'],random_state=3009)\n",
    "displayResults(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ionosphere dataset\n",
    "#splitting the dataset\n",
    "train_size=round(ionosphere.shape[0]*0.75)\n",
    "X_train=np.asarray([ionosphere[i][:-1] for i in range(0,train_size)])\n",
    "X_test=np.asarray([ionosphere[i][:-1] for i in range(train_size,ionosphere.shape[0])])\n",
    "y_train=np.asarray([ionosphere[i][-1] for i in range(0,train_size)])\n",
    "y_test=np.asarray([ionosphere[i][-1] for i in range(train_size,ionosphere.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p-values': array([0.31908832, 0.002849  , 0.18518519, 0.002849  , 0.11396011,\n",
       "        0.35042735, 0.00854701, 0.18518519, 0.37321937, 0.06837607,\n",
       "        0.01709402, 0.02279202, 0.00854701, 0.02849003, 0.44444444,\n",
       "        0.01424501, 0.01709402, 0.11111111, 0.29344729, 0.17663818,\n",
       "        0.68091168, 0.08262108, 0.34188034, 0.26495726, 0.17948718,\n",
       "        0.002849  , 0.25925926, 0.29344729, 0.64672365, 0.00569801,\n",
       "        0.00854701, 0.02849003, 0.46153846, 0.01994302, 0.10826211,\n",
       "        0.01994302, 0.08262108, 0.27635328, 0.4985755 , 0.01424501,\n",
       "        0.02279202, 0.05413105, 0.56125356, 0.1025641 , 0.34188034,\n",
       "        0.05982906, 0.15384615, 0.23931624, 0.34472934, 0.11396011,\n",
       "        0.11111111, 0.0997151 , 0.37891738, 0.35042735, 0.4017094 ,\n",
       "        0.16524217, 0.46438746, 0.15384615, 0.71794872, 0.07977208,\n",
       "        0.23646724, 0.14245014, 0.74074074, 0.03418803, 0.13675214,\n",
       "        0.00569801, 0.12820513, 0.05128205, 0.04273504, 0.07692308,\n",
       "        0.35612536, 0.0968661 , 0.17663818, 0.05128205, 0.77777778,\n",
       "        0.00854701, 0.02279202, 0.1025641 , 0.32193732, 0.14245014,\n",
       "        0.33618234, 0.14814815, 0.02849003, 0.01424501, 0.08262108,\n",
       "        0.00569801, 0.13960114, 0.04273504, 0.46153846, 0.03133903,\n",
       "        0.05413105, 0.12250712, 0.23646724, 0.07122507, 0.09116809,\n",
       "        0.01424501, 0.16809117, 0.50712251, 0.14814815, 0.23076923,\n",
       "        0.03988604, 0.1994302 , 0.44159544, 0.60683761, 0.11396011,\n",
       "        0.43304843, 0.03703704, 0.47578348, 0.22507123, 0.01424501,\n",
       "        0.11965812, 0.25641026, 0.33903134, 0.78062678, 0.05128205,\n",
       "        0.002849  , 0.01424501, 0.3019943 , 0.27920228, 0.39031339,\n",
       "        0.01139601, 0.17663818, 0.18233618, 0.32763533, 0.1965812 ,\n",
       "        0.34188034, 0.04273504, 0.07122507, 0.01139601, 0.04273504,\n",
       "        0.22507123, 0.26495726, 0.3048433 , 0.02849003, 0.28205128,\n",
       "        0.76353276, 0.05128205, 0.15099715, 0.43019943, 0.03133903,\n",
       "        0.22507123, 0.20797721, 0.02849003, 0.002849  , 0.02279202,\n",
       "        0.27065527, 0.31054131, 0.07692308, 0.18233618, 0.78062678,\n",
       "        0.05413105, 0.04843305, 0.0968661 , 0.02849003, 0.19088319,\n",
       "        0.37606838, 0.02564103, 0.07122507, 0.22222222, 0.30769231,\n",
       "        0.38461538, 0.60968661, 0.03703704, 0.2022792 , 0.00569801,\n",
       "        0.02564103, 0.00569801, 0.0997151 , 0.39316239, 0.29059829,\n",
       "        0.09401709, 0.04273504, 0.30769231, 0.13960114, 0.03418803,\n",
       "        0.56410256, 0.03988604, 0.5042735 , 0.05698006, 0.15669516,\n",
       "        0.11396011, 0.35042735, 0.07122507, 0.03703704, 0.11396011,\n",
       "        0.03703704, 0.09116809, 0.27920228, 0.04558405, 0.01709402,\n",
       "        0.25641026, 0.00569801, 0.13675214, 0.32763533, 0.36467236,\n",
       "        0.27920228, 0.15954416, 0.43304843, 0.04558405, 0.34188034,\n",
       "        0.002849  , 0.21082621, 0.05128205, 0.16809117, 0.09116809,\n",
       "        0.01709402, 0.11396011, 0.28490028, 0.0997151 , 0.21367521,\n",
       "        0.12535613, 0.31339031, 0.07977208, 0.18233618, 0.17948718,\n",
       "        0.63532764, 0.07977208, 0.48148148, 0.21937322, 0.2962963 ,\n",
       "        0.06552707, 0.2991453 , 0.02564103, 0.18233618, 0.17663818,\n",
       "        0.3960114 , 0.07692308, 0.04558405, 0.13390313, 0.02564103,\n",
       "        0.43304843, 0.03703704, 0.17948718, 0.24501425, 0.002849  ,\n",
       "        0.13390313, 0.00854701, 0.43019943, 0.02849003, 0.48148148,\n",
       "        0.13390313, 0.82621083, 0.05128205, 0.74643875, 0.26210826,\n",
       "        0.05128205, 0.01139601, 0.14529915, 0.44159544, 0.33333333,\n",
       "        0.09116809, 0.04558405, 0.19088319, 0.52136752, 0.02564103,\n",
       "        0.03988604, 0.51566952, 0.12820513, 0.15954416, 0.53846154,\n",
       "        0.13675214, 0.24501425, 0.18803419, 0.57834758, 0.43874644,\n",
       "        0.65527066, 0.31623932, 0.35327635, 0.25356125, 0.05698006,\n",
       "        0.54131054, 0.22222222, 0.38746439, 0.15669516, 0.05698006,\n",
       "        0.15099715, 0.3048433 , 0.53846154, 0.08547009, 0.51566952,\n",
       "        0.17378917, 0.12250712, 0.84330484, 0.48433048, 0.39316239,\n",
       "        0.07977208, 0.2962963 , 0.41310541, 0.18518519, 0.17663818,\n",
       "        0.02279202, 0.05982906, 0.18803419, 0.33333333, 0.15384615,\n",
       "        0.07977208, 0.03418803, 0.53846154, 0.06552707, 0.38461538,\n",
       "        0.60683761, 0.60968661, 0.65811966, 0.48433048, 0.04273504,\n",
       "        0.01424501, 0.15669516, 0.33903134, 0.17094017, 0.47008547,\n",
       "        0.17663818, 0.0968661 , 0.20512821, 0.48717949, 0.45014245,\n",
       "        0.43589744, 0.85754986, 0.28490028, 0.16524217, 0.04558405,\n",
       "        0.05982906, 0.53561254, 0.03418803, 0.30769231, 0.39316239,\n",
       "        0.71509972, 0.05698006, 0.29344729, 0.12250712, 0.76923077,\n",
       "        0.48717949, 0.58689459, 0.72649573, 0.36182336, 0.04273504,\n",
       "        0.24216524, 0.6039886 , 0.06267806, 0.1994302 , 0.34472934,\n",
       "        0.2022792 , 0.54985755, 0.33903134, 0.2022792 , 0.04843305,\n",
       "        0.31908832, 0.28490028, 0.77207977, 0.54415954, 0.24501425,\n",
       "        0.20512821]),\n",
       " 'Predicted list': array([ 1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " 'Average False P-value': 0.0011769384988758208,\n",
       " 'Error Rate': 0.03409090909090906,\n",
       " 'Number of errors': 2}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayResults(X_train,y_train,X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
